{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrutikaBhavsar/machine-learning-/blob/main/assignment02/CNN_for_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTdpKSwXnvzl"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6J1WIXrnvzl",
        "outputId": "d5879f37-c3bb-435c-c8d8-1e2b0ec1b5a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-18 17:28:14--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py.1’\n",
            "\n",
            "\rnetwork.py.1          0%[                    ]       0  --.-KB/s               \rnetwork.py.1        100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-18 17:28:14 (30.3 MB/s) - ‘network.py.1’ saved [1469/1469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "# !curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "# !tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "# data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUWkpd7PycOQ",
        "outputId": "214a953b-ae49-4754-d9f1-46957d7acd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:26, 9178.06it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP_YhgOQnvzo",
        "outputId": "e6ad161d-5abd-4721-d75b-b06e5de62d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "be77ba9a-4cea-4e41-cc6d-d38f5edaa17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "45ab8532-cdc9-4079-83e7-64d749623e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "df52e87d-8696-47a6-8b60-91c6247b6fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "12ee6a1d-7251-4d63-abad-e2d5c307c3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-6Vm98tnvzr"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePGLx2jInvzs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zWkcmdgnvzs"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lj6Ng2Ynvzs"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsyM88mmnvzs"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsmO6pZOnvzt"
      },
      "outputs": [],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3uy2Q-Knvzt"
      },
      "outputs": [],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgiqEoIDnvzt",
        "outputId": "fdf1650f-912b-4df4-ea54-04b05680a9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[19217, 26688,  7252,     1],\n",
              "        [29096, 18670,  8895, 33628],\n",
              "        [10868,  7468,     1,     1]], dtype=int32),\n",
              " 'FullDescription': array([[29654, 20742, 14109, ...,     1,     1,     1],\n",
              "        [25927, 16658, 21721, ...,     1,     1,     1],\n",
              "        [10868,  7468,  3551, ..., 10572,  4938,   167]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5N-q5wVnvzt"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RLdWPY0nvzu",
        "outputId": "7e45512e-33fc-4494-9ac8-d78e251dad08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2805],\n",
              "        [0.2820],\n",
              "        [0.2546]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSdwwOA7nvzu",
        "outputId": "11d9b55a-f7a3-4f77-fe99-f3799f1c64fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 428)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lznGHvJBnvzu"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fjrwoIynvzv"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import clear_output\n",
        "# from random import sample\n",
        "\n",
        "# epochs = 1\n",
        "\n",
        "# model = simple_model\n",
        "# opt = torch.optim.Adam(model.parameters())\n",
        "# loss_func = nn.MSELoss()\n",
        "\n",
        "# history = []\n",
        "# for epoch_num in range(epochs):\n",
        "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "#         # Preprocessing the batch data and target\n",
        "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "#         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "#         predictions = model(batch)\n",
        "#         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "#         # train with backprop\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "#         # <YOUR CODE HERE>\n",
        "\n",
        "#         history.append(loss.data.numpy())\n",
        "#         if (idx+1)%10==0:\n",
        "#             clear_output(True)\n",
        "#             plt.plot(history,label='loss')\n",
        "#             plt.legend()\n",
        "#             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlDFUnR9nvzv"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mIwBKX1nvzw"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AcAyRcRnvzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2013ddd4-8bd6-43d8-f2c4-d2f5bfdd8512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFVW8mLBnvzw"
      },
      "outputs": [],
      "source": [
        "hid_size = 64\n",
        "concat_number_of_features = 2 * hid_size + hid_size\n",
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "    concat_number_of_features=concat_number_of_features,\n",
        "    hid_size=hid_size\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfxkrTm5nvzx"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1oYIjfnvzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06b467b-4ebf-4c9f-f61d-c6bc67960b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dQCYqmmnvzx"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WksGxmvenvzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "44c6acca-dfb9-4c75-e145-cf627e540053"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (input_batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        title_ix = torch.tensor(input_batch['Title'], dtype=torch.long).to(device)\n",
        "        desc_ix = torch.tensor(input_batch['FullDescription'], dtype=torch.long).to(device)\n",
        "        cat_features = torch.tensor(input_batch['Categorical'], dtype=torch.long).to(device)\n",
        "        target = torch.tensor(target, dtype=torch.float32).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model((title_ix, desc_ix, cat_features))\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_func(predictions, target)\n",
        "\n",
        "        # Train with backpropagation\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history, label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        if idx + 1 >= 100:  # Stop after 100 batches\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyk8sZQbnvzx"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKkfQ6cdnv0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970dc6f4-8e72-483c-9f2e-6a1ac347f787"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (category_emb): Embedding(3746, 64)\n",
              "  (category_out): Linear(in_features=239744, out_features=64, bias=True)\n",
              "  (inter_dense): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGRH1LICnv0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbc228e-a21a-4705-806d-33132c23eb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:01, 19.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 5.49948\n",
            "Mean absolute error: 2.29818\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    model = model.to(device)  # Move the model to the correct device\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long).to(device),  # Move tensors to the correct device\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device),\n",
        "                torch.tensor(batch_x['Categorical']).to(device)\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().cpu().numpy()  # Move the predictions back to the CPU\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBlVia_tnv0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba5cf38-f177-4235-b7cf-4e0d9680db54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:00, 23.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 5.49948\n",
            "Mean absolute error: 2.29818\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLC6zHznv0T"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}